# 问题分析与解决方案

## 一、现状数据

来自 `result/selected_k_total_summary.csv`：

| k | best_val_acc | test_acc_ali (源域) | test_acc_megvii (跨域) |
|---|---|---|---|
| -1 (原模型) | 0.9475 | 0.950 | 0.744 |
| 32 | 0.93 | 0.915 | 0.781 |
| 64 | 0.9175 | 0.905 | 0.725 |
| 128 | 0.9125 | 0.915 | 0.727 |

现象：
- k=32 时，ali 准确率下降约 3.5%，但 megvii 跨域提升约 3.7%
- k=64、128 时，ali 下降更多，megvii 反而也变差了

---

## 二、对你的猜想的点评

### 猜想 1："贪心选取通道时没有考虑通道与模型准确性能之间的关系"

**部分正确。** NMI 衡量的是"特征与标签的统计相关性"，它和"分类准确率"是两个不同的指标。某些通道的 NMI 可能不高，但对分类决策很重要（比如提供了关键的判别边界信息）。不过，NMI 作为选择准则本身并不差——更大的问题在于后面的训练方式（见第三节）。

### 猜想 2："没有考虑通道组合效应"

**有道理，但你的贪心法已经部分解决了这个问题。** 贪心法在每一步都评估"当前子空间+候选通道"的整体 NMI，所以它考虑了已选通道与候选通道的组合效果。但贪心法是局部最优，无法保证全局最优，确实可能遗漏某些"单独弱但组合强"的通道。

---

## 三、我发现的根本原因

### 根因 1（最关键）：backbone 没有加载预训练权重

这是源域准确率下降的**核心原因**。

查看 `newtrain.py` 中的模型定义：

```python
class EfficientNetB0SelectedChannels(nn.Module):
    def __init__(self, num_classes, selected_indices, dropout=0.2):
        super().__init__()
        self.backbone = EfficientNetB0(num_classes=num_classes)  # ← 随机初始化！
```

这里的 `EfficientNetB0` 是**从零开始的随机权重**，完全没有加载 `OriginalModel.pth` 的预训练参数。

这导致了一个严重的矛盾：
- 通道选择器是基于**预训练模型**提取的 1280 维特征做的（ChannelSelect.py 用的是 OriginalModel 的特征）
- 但训练时用的是**随机初始化的 backbone**，它输出的 1280 维特征和预训练模型完全不同
- 也就是说，你精心挑选的通道对应的是预训练特征空间中的"好通道"，但对于随机 backbone 来说毫无意义
- 模型必须从零学习所有特征表示，但特征空间又被限制在 k 个通道，学习难度更大

**结果**：模型收敛到一个比原模型差的解，源域准确率必然下降。

### 根因 2：训练策略不够精细

当前训练配置：
- 所有参数（backbone + FC head）使用相同的学习率 `lr=1e-4`
- 没有 weight_decay（L2 正则化）
- 没有学习率调度器

对于"加载预训练 backbone + 新 FC head"这种迁移学习场景：
- backbone 已经有好的特征表示，只需要微调，应该用**小学习率**
- FC head 是全新的，需要快速学习，应该用**大学习率**
- 缺少 L2 正则化，容易在源域上过拟合，损害跨域泛化

### 根因 3（次要）：通道选择只看 NMI 不看分类准确率

NMI 是一个好的统计指标，但如果同时参考"选出的通道子集在 LogReg 分类器上的准确率"，可以更直接地保证所选通道具有分类能力。

---

## 四、解决方案

### 方案 1（核心修改）：newtrain.py 加载预训练 backbone + 改进训练策略

具体改动：

1. **加载预训练权重**：在创建 `EfficientNetB0SelectedChannels` 后，把 `OriginalModel.pth` 的权重加载到 `self.backbone` 中
2. **差异化学习率**：backbone 用小学习率（如 1e-5），FC head 用大学习率（如 1e-3）
3. **添加 weight_decay**：L2 正则化（如 1e-4），防止过拟合
4. **添加学习率调度器**：ReduceLROnPlateau，当验证集准确率不提升时自动降低学习率
5. **可选的 backbone 冻结**：前几个 epoch 冻结 backbone 只训练 FC head，再放开全部微调
6. **记录每个 epoch 的训练/验证准确率到 CSV**：方便分析训练曲线

### 方案 2：newtest.py 同时测试源域和跨域

改动：同时在 ali/test 和 megvii/test 上测试，输出一张汇总表，方便对比。

### 方案 3（可选增强）：ChannelSelect.py 增加分类准确率指标

在贪心通道选择过程中，除了记录 NMI 以外，额外记录 LogReg 分类准确率作为参考。目前不改变选择准则（仍用 NMI），但提供更多可观测指标。如果后续发现 NMI 选出的通道分类准确率不好，可以考虑用混合指标。

---

## 五、预期效果

| 改动 | 对源域的影响 | 对跨域的影响 |
|---|---|---|
| 加载预训练 backbone | 准确率大幅回升（接近原模型） | 保持或提升 |
| 差异化学习率 | 更稳定的收敛，小幅提升 | 小幅提升 |
| weight_decay 正则化 | 防止过拟合，准确率更稳 | 提升（减少过拟合到源域） |
| 学习率调度器 | 更好收敛 | 间接提升 |
| 通道筛选（k 较小） | 略微下降（信息瓶颈） | 提升（减少冗余通道的过拟合） |

核心逻辑：
- 加载预训练权重 → 恢复源域准确率
- 通道筛选 + 正则化 → 作为信息瓶颈防止过拟合 → 提升跨域泛化
- 两者结合 → 源域不太掉 + 跨域提升

---

## 六、涉及修改的文件

| 文件 | 改动内容 |
|---|---|
| `newtrain.py` | 加载预训练 backbone 权重；差异化学习率；weight_decay；学习率调度器；可选 backbone 冻结；per-epoch CSV 日志 |
| `newtest.py` | 同时测试 ali 和 megvii；输出包含双域测试结果的汇总 CSV |
